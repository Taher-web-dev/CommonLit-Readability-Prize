<img src = "https://upload.wikimedia.org/wikipedia/commons/7/7c/Kaggle_logo.png" alt="kaggle logo" width="10%">
<img src = "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRPjmWECCEXeGU23gwv8QqyxLGy014eKnNOVw&usqp=CAU" width="10%"  alt="Riid-logo height="15%">


# Kaggle project  : CommonLit-Readability-Prize
CommonLit, Inc., is a nonprofit education technology organization serving over 20 million teachers and students with free digital reading and writing lessons for grades 3-12. Together with Georgia State University, an R1 public research university in Atlanta, they are challenging Kagglers to improve readability rating methods. In this competition, we had built algorithms to rate the complexity of reading passages for grade 3-12 classroom use. To accomplish this, we had used state of the art machine learning tools with a dataset that includes readers from a wide variety of age groups and a large collection of texts taken from various domains.<br/>
You can find three version of trials :<br/>
EDA + LSTM +CNN : In this version, we had passed by an exploration data analysis step , which had allowed us to explore and extraxct valuable insights. Then, we had used an LSTM model which had gave us  a good start result in compare with the benchmark results of kagglers competitors. Finaly, we had test a CNN model , which had gave a slightly better result than LSTM .<br/>        
Roberta Model : We had used roberta model, to resolve this problem. So , we had trained a Roberta model using our dataset , then we had fine tunned this model using our target, finally we had combined this model with LGBM model in order to define our model of forecasting.<br/>      
Bert Model : As we had done with Roberta model , we had adopt the same approach for Bert model.Except that we combined bert with SVM model in  order to make our forecasting.   

<img src="https://passle-net.s3.amazonaws.com/Passle/5e8c837d3dccd208784b7527/MediaLibrary/Images/5e9db597fac8ca09300c94ba/2021-08-04-10-20-50-782-610a6a02400fb312b4f0000a.png" width=100%>


## Built With üî®

- Kaggle platform.
- Python. 
- Pytorch.
- Tensorflow.
- Bert 
- Roberta
- LSTM
- CNN
- LGBM
- SVM

## Live Demo

[Live Demo Link](https://www.kaggle.com/c/commonlitreadabilityprize/code?competitionId=25914&sortBy=dateRun&tab=profile)

### Install

To get a local copy up and running follow these simple example steps.
- Open terminal
- Clone this project by the command: 

```
$ git clone git@github.com:Taher-web-dev/CommonLit-Readability-Prize.git
```

- Then go to the main folder using the next command:

```
$ cd CommonLit-Readability-Prize
```




### Prerequisites

- IDE to edit and run the code (We use Jupyter Notebook üî•).
- Git to versionning your work.


### Usage

- Data scientist practioner
- For anyone interested by NLP topics.


## Authors

üë§ **Taher Haggui**

- GitHub: [@TaherHaggui](https://github.com/Taher-web-dev)
- LinkedIn: [@TaherHaggui](https://www.linkedin.com/in/taher-haggui-66b5a6198/)


## ü§ù Contributing

Contributions, issues, and feature requests are welcome!



## Show your support

Give a ‚≠êÔ∏è if you like this project!


## Acknowledgments
- kaggle plarform  üíò (https://www.kaggle.com/)
- My family's support üôå

## üìù License

This project is [CommonLit](https://www.commonlit.org/) licensed.
      
